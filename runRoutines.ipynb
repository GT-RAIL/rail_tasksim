{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maithili/repos/tasksim/.venv/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('simulation')\n",
    "from unity_simulator.comm_unity import UnityCommunication\n",
    "from dataset_utils import execute_script_utils as utils\n",
    "from evolving_graph import scripts\n",
    "\n",
    "def setup():\n",
    "    comm = UnityCommunication()\n",
    "    return comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching all scripts and running them to filter the ones that run on sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET = 'dataset/programs_processed'\n",
    "# list_of_scene_scripts = glob.glob('{}/executable_programs/TrimmedTestScene{}_graph/*/*.txt'.format(DATASET,'1'))\n",
    "def graph_file_from_script(script_file):\n",
    "    return script_file.replace('executable_programs','init_and_final_graphs').replace('.txt','.json')\n",
    "\n",
    "def process_file_inbuilt(script_file, graph_file):\n",
    "    return utils.render_script_from_path(setup(),\n",
    "                                script_file, graph_file,\n",
    "                                {\"processing_time_limit\": 500, \"image_width\": 320, \"image_height\": 240, \"image_synthesis\": ['normal'], \"gen_vid\": True, \"file_name_prefix\": \"test\", \"camera_mode\": 'PERSON_TOP'}, scene_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # These were found to get the simulator stuck...\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_text_rebuttal_specialparsed_programs_turk_third/split36_2.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file241_1.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file416_2.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file211_1.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file474_2.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file287_2.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file99_2.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file482_2.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file352_1.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file442_2.txt')\n",
    "# list_of_scene_scripts.remove('dataset/programs_processed/executable_programs/TrimmedTestScene1_graph/results_text_rebuttal_specialparsed_programs_upwork_july/split23_9.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Total scripts to go through : ',len(list_of_scene_scripts))\n",
    "# usable_scripts = []\n",
    "# try:\n",
    "#     for i,script_file in enumerate(list_of_scene_scripts):\n",
    "#         res = process_file_inbuilt(script_file, graph_file_from_script(script_file))\n",
    "#         success = res['success_expand']\n",
    "#         if 'success_exec' in res.keys():\n",
    "#             success = success and res['success_exec']\n",
    "#         if success:\n",
    "#             usable_scripts.append(script_file)\n",
    "#         if i%50 == 0:\n",
    "#             print(f'Processed {i} scripts')\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "# finally:\n",
    "#     print(i,' files processed')\n",
    "    # print('Last processed :',script_file)\n",
    "    # print(len(usable_scripts))\n",
    "    # with open(DATASET+'/usable_scripts.txt','a') as f:\n",
    "    #     for s in usable_scripts:\n",
    "    #         f.write(s+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize the usable script by activity and save in short_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     assert(len(usable_scripts) > 0)\n",
    "# except:\n",
    "#     usable_scripts = []\n",
    "#     with open(DATASET+'/usable_scripts.txt','r') as f:\n",
    "#         for line in f:\n",
    "#             usable_scripts.append(line[:-1])\n",
    "# print(len(usable_scripts))\n",
    "\n",
    "# activities = {}\n",
    "# for script in usable_scripts:\n",
    "#     with open(script,'r') as f:\n",
    "#         activity = f.readline().strip()\n",
    "#         if activity in activities:\n",
    "#             activities[activity].append(script)\n",
    "#         else:\n",
    "#             activities[activity]=[script]\n",
    "# for act in activities:\n",
    "#     print (act,len(activities[act]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching all scripts and running them to filter the ones that run on sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual Work here!!!\n",
    "# activity_categories = {}\n",
    "# activity_categories['morning'] = ['Take shower', 'Turn on light', 'Open front door','Open door']\n",
    "# activity_categories['night'] = ['Turn off light', 'Walk to room', 'Lock door']\n",
    "# activity_categories['pastime'] = ['Read book', 'Read', 'Do work', 'Pet cat', 'Pick up phone', 'Go to toilet', 'Relax on sofa', 'Browse internet', 'Listen to music', 'Watch TV', 'Admire art']\n",
    "# activity_categories['chore'] = ['Change sheets and pillow cases', 'Find dictionary','Put away shoes']\n",
    "# activity_categories['food_pre'] = []\n",
    "# activity_categories['food_post'] = ['Bring dirty plate to sink', ]\n",
    "# activity_categories['unknown'] = ['Turn off TV', 'Bring me red cookbook', 'Close door', 'Keep cats out of room']\n",
    "\n",
    "# activity_scripts = {key:[] for key in activity_categories.keys()}\n",
    "\n",
    "# for act,scripts in activities.items():\n",
    "#     for k,v in activity_categories.items():\n",
    "#         if act in v:\n",
    "#             activity_scripts[k] = activity_scripts[k] + scripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shutil import copyfile\n",
    "\n",
    "# # for act, scripts in activity_scripts.items():\n",
    "# #     os.makedirs('dataset/short_scripts/withoutconds/'+act)\n",
    "# #     print(act, len(scripts))\n",
    "# #     for script in scripts:\n",
    "# #         script = script.replace('executable_programs/TrimmedTestScene1_graph','withoutconds')\n",
    "# #         copyfile(script, 'dataset/short_scripts/withoutconds/'+act+'/'+os.path.basename(script))\n",
    "\n",
    "# activity_scripts = {}\n",
    "# base_dir = 'dataset/short_scripts/withoutconds/'\n",
    "# for dir in glob.glob('{}/*'.format(base_dir)):\n",
    "#     activity_scripts[os.path.basename(dir)] = glob.glob('{}/*.txt'.format(dir))\n",
    "\n",
    "# for act,scripts in activity_scripts.items():\n",
    "#     print (act, len(scripts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate concatenated scripts for full-day routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# routine_components = ['morning','night','pastime','chore','food_post']\n",
    "# routine_sequence = ['morning','chore','pastime','food_post','pastime','chore','food_post','pastime','night']\n",
    "\n",
    "# def write_script(script, file_name, script_name='', script_desc=''):\n",
    "#     with open(file_name, 'w') as f:\n",
    "#         f.write(script_name+'\\n')\n",
    "#         f.write(script_desc+'\\n\\n\\n')\n",
    "#         for s in script:\n",
    "#             f.write(s+'\\n')\n",
    " \n",
    "\n",
    "# def sample_script():\n",
    "#     script = []\n",
    "#     for segment in routine_sequence:\n",
    "#         segment_script_files = glob.glob('dataset/short_scripts/withoutconds/{}/*.txt'.format(segment))\n",
    "#         file_name = random.choice(segment_script_files)\n",
    "#         with open(file_name) as f:\n",
    "#             for line in f:\n",
    "#                 if '[' in line:\n",
    "#                     script.append(line.strip())\n",
    "#     return script\n",
    "\n",
    "\n",
    "# !rm -r 'dataset/long_scripts'\n",
    "# !mkdir -p 'dataset/long_scripts/withoutconds/batch1'\n",
    "# for i in range(50):\n",
    "#     write_script(sample_script(), 'dataset/long_scripts/withoutconds/batch1/'+str(i)+'.txt', 'Randomly generated routine', str(routine_sequence)[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add preconditions for scripts + Create initial graphs and execute scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts now run on their own init graph. How to generate an init graph for a sequence? Complete and fix the scripts manually then concatenate and try creating init graph and executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/my_scripts/withoutconds/breakfast_weekday_1/complete.txt',\n",
       " 'dataset/my_scripts/withoutconds/laundry/complete.txt',\n",
       " 'dataset/my_scripts/withoutconds/meal/complete.txt',\n",
       " 'dataset/my_scripts/withoutconds/breakfast_weekday_2/complete.txt',\n",
       " 'dataset/my_scripts/withoutconds/breakfast_weekend/complete.txt',\n",
       " 'dataset/my_scripts/withoutconds/icecream/complete.txt',\n",
       " 'dataset/my_scripts/withoutconds/sleep/complete.txt',\n",
       " 'dataset/my_scripts/withoutconds/read/complete.txt',\n",
       " 'dataset/my_scripts/withoutconds/meal_long/complete.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "path_input = 'dataset/my_scripts'\n",
    "glob.glob('{}/withoutconds/*/*.txt'.format(path_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekday_1/0.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekday_1/1.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekday_1/2.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekday_1/3.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekday_1/complete.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekend/0.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekend/1.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekend/2.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekend/3.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/breakfast_weekend/complete.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/icecream/0.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/icecream/1.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/icecream/2.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/icecream/3.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/icecream/4.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/icecream/complete.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/laundry/0.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/laundry/1.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/laundry/2.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/laundry/complete.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal/0.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal/1.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal/2.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal/3.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal/complete.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal_long/0.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal_long/1.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal_long/2.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal_long/3.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal_long/4.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal_long/5.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal_long/6.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/meal_long/complete.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/read/0.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/read/1.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/read/2.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/read/complete.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/sleep/0.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/sleep/1.txt\n",
      "Adding preconds for  dataset/my_scripts/withoutconds/sleep/complete.txt\n"
     ]
    }
   ],
   "source": [
    "### Test-A-Script\n",
    "\n",
    "path_input = 'dataset/my_scripts'\n",
    "\n",
    "from shutil import rmtree\n",
    "if os.path.exists('{}/executable_programs'.format(path_input)):\n",
    "    rmtree('{}/executable_programs'.format(path_input))\n",
    "    rmtree('{}/init_and_final_graphs'.format(path_input))\n",
    "    rmtree('{}/initstate'.format(path_input))\n",
    "    rmtree('{}/state_list'.format(path_input))\n",
    "\n",
    "# script_path = 'dataset/test_script/withoutconds/test/1.txt'\n",
    "%run -i 'dataset_utils/add_preconds.py'\n",
    "%run -i 'simulation/evolving_graph/check_programs.py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4987.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total programs: 0, executable programs: 0 (unique: 0)\n",
      "Programs that can not be parsed: 0 (unique: 0)\n",
      "Executable program average length: 0.00, not executable program average length: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_input = 'dataset/my_scripts/withoutconds/breakfast_weekday_1/0.txt'\n",
    "# path_input = 'dataset/my_scripts/withoutconds/laundry/complete.txt'\n",
    "# path_input = 'dataset/my_scripts/withoutconds/meal/complete.txt'\n",
    "# path_input = 'dataset/my_scripts/withoutconds/breakfast_weekday_2/complete.txt'\n",
    "# path_input = 'dataset/my_scripts/withoutconds/breakfast_weekend/complete.txt'\n",
    "# path_input = 'dataset/my_scripts/withoutconds/icecream/complete.txt'\n",
    "# path_input = 'dataset/my_scripts/withoutconds/sleep/complete.txt'\n",
    "# path_input = 'dataset/my_scripts/withoutconds/read/complete.txt'\n",
    "# path_input = 'dataset/my_scripts/withoutconds/meal_long/complete.txt'\n",
    "\n",
    "translated_path = 'dataset/my_scripts/initial_common.json'\n",
    "\n",
    "%run -i 'simulation/evolving_graph/check_programs.py'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/my_scripts/init_and_final_graphs/initial_common/read/complete.json\n",
      "{'nodes': {'removed': [], 'added': []}, 'edges': {'removed': [], 'added': []}}\n"
     ]
    }
   ],
   "source": [
    "with open(translated_path,'r') as f:\n",
    "    g1 = json.load(f)\n",
    "# new_graph_path = 'dataset/my_scripts/temp.json'\n",
    "new_graph_path = path_input.replace('withoutconds','init_and_final_graphs/initial_common').replace('.txt','.json')\n",
    "print(new_graph_path)\n",
    "with open (new_graph_path, 'r') as f:\n",
    "    g2 = json.load(f)\n",
    "g2 = g2['init_graph']\n",
    "diff = {'nodes':{},'edges':{}}\n",
    "def character_edge(e):\n",
    "    return class_from_id(g1, e['from_id']) == 'character' or class_from_id(g1, e['to_id']) == 'character'\n",
    "diff['edges']['removed'] = [e for e in g1['edges'] if e not in g2['edges'] and not character_edge(e)]\n",
    "diff['edges']['added'] = [e for e in g2['edges'] if e not in g1['edges'] and not character_edge(e)]\n",
    "diff['nodes']['removed'] = [n for n in g1['nodes'] if n['id'] not in [n2['id'] for n2 in g2['nodes']]]\n",
    "diff['nodes']['added'] = [n for n in g2['nodes'] if n['id'] not in [n2['id'] for n2 in g1['nodes']]]\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(translated_path,'w') as f:\n",
    "    json.dump(g2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comm = setup()\n",
    "# comm.reset(0)\n",
    "# s, graph = comm.environment_graph()\n",
    "\n",
    "# ignore_classes = ['floor','wall','ceiling']\n",
    "# rooms = ['bathroom', 'bedroom', 'livingroom', 'kitchen']\n",
    "# significant_classes = set()\n",
    "\n",
    "def class_from_id(graph, id):\n",
    "    lis = [n['class_name'] for n in graph['nodes'] if n['id']==id]\n",
    "    if len(lis) > 0:\n",
    "        return lis[0]\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "def edge_string(graph, edge):\n",
    "    from_class = class_from_id(graph, edge['from_id'])\n",
    "    from_id = ' ('+str(edge['from_id'])+' )'\n",
    "    to_class = class_from_id(graph, edge['to_id'])\n",
    "    to_id = ' ('+str(edge['to_id'])+' )'\n",
    "    return from_class+from_id+e['relation_type']+to_class+to_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dataset/my_scripts/initial_common.json','r') as f:\n",
    "    my_graph = json.load(f)\n",
    "\n",
    "print('Original my graph has ',len(my_graph['nodes']),' nodes and ',len(my_graph['edges']),' edges')\n",
    "\n",
    "categories = set([n['category'] for n in my_graph['nodes']])\n",
    "print(categories)\n",
    "\n",
    "\n",
    "use_graph = {'nodes':[], 'edges':[]}\n",
    "use_ids = []\n",
    "class_ids = {}\n",
    "for n in my_graph['nodes']:\n",
    "    if n['category'] in [\"Rooms\", \"Furniture\", \"Appliances\", \"placable_objects\", \"Characters\"]:\n",
    "        use_ids.append(n['id'])\n",
    "        use_graph['nodes'].append(n)\n",
    "    if n['class_name'] not in class_ids:\n",
    "        class_ids[n['class_name']] = n['id']\n",
    "for e in my_graph['edges']:\n",
    "    if e['from_id'] in use_ids and e['to_id'] in use_ids:\n",
    "        use_graph['edges'].append(e)\n",
    "\n",
    "class_ids['kitchen'] = class_ids['dining_room']\n",
    "\n",
    "print('My trimmed graph has ',len(use_graph['nodes']),' nodes and ',len(use_graph['edges']),' edges')\n",
    "print (class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_node_ids = [n['id'] for n in my_graph['nodes'] if n['category'] == 'Rooms']\n",
    "print(room_node_ids)\n",
    "for e in my_graph['edges']:\n",
    "    if e['to_id'] in room_node_ids:\n",
    "        if e['relation_type'] != 'INSIDE':\n",
    "            print(edge_string(my_graph,e))\n",
    "    if e['from_id'] in room_node_ids:\n",
    "            print(edge_string(my_graph,e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph['nodes'])\n",
    "for r in rooms:\n",
    "    print()\n",
    "    print(r)\n",
    "    for e in graph['edges']:\n",
    "        if class_from_id(graph, e['to_id']) == r and class_from_id(graph, e['from_id']) not in ignore_classes:\n",
    "            print(class_from_id(graph, e['from_id']), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "significant_classes = set()\n",
    "file_names = glob('dataset/good_scripts/state_list/TrimmedTestScene1_graph/*/complete.json')\n",
    "wierd_classes = ['mat', 'drawing', 'toaster']\n",
    "\n",
    "def get_difference(g1, g2):\n",
    "    diff = {}\n",
    "    def character_edge(e):\n",
    "        return class_from_id(g1, e['from_id']) == 'character' or class_from_id(g1, e['to_id']) == 'character'\n",
    "    diff['removed'] = [e for e in g1['edges'] if e not in g2['edges'] and not character_edge(e)]\n",
    "    diff['added'] = [e for e in g2['edges'] if e not in g1['edges'] and not character_edge(e)]\n",
    "    return diff\n",
    "\n",
    "def print_graph_difference(g, diff):\n",
    "    print('Removed...')\n",
    "    for e in diff['removed']:\n",
    "        print(edge_string(g, e))\n",
    "    print('Added...')\n",
    "    for e in diff['added']:\n",
    "        print(edge_string(g, e))\n",
    "\n",
    "def append_changed_classes(g, diff):\n",
    "    for e in diff['removed']+diff['added']:\n",
    "        if class_from_id(g, e['from_id']) in wierd_classes or class_from_id(g, e['to_id']) in wierd_classes:\n",
    "            print(edge_string(g, e))\n",
    "        significant_classes.add(class_from_id(g, e['from_id']))\n",
    "        significant_classes.add(class_from_id(g, e['to_id']))\n",
    "\n",
    "# for file_name in file_names:\n",
    "#     with open(file_name) as f:\n",
    "#         data = json.load(f)\n",
    "#     data = data['graph_state_list']\n",
    "#     print(file_name.split('/')[-2],' edges : ',len(data[0]['edges']),' nodes : ',len(data[0]['nodes']))\n",
    "#     for i,(g1,g2) in enumerate(zip(data[0:-1],data[1:])):\n",
    "#         append_changed_classes(g1, get_difference(g1, g2))\n",
    "#     print_graph_difference(data[0], get_difference(data[0], data[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.evolving_graph.execution import ScriptExecutor\n",
    "from simulation.evolving_graph.utils import load_name_equivalence\n",
    "from simulation.evolving_graph.check_programs import dump_one_data, modify_objects_unity2script\n",
    "\n",
    "script_file_paths = glob.glob('dataset/my_scripts/withoutconds/*/complete.txt')\n",
    "\n",
    "name_equivalence = load_name_equivalence()\n",
    "complete_class_ids = class_ids.copy()\n",
    "for c1,c2s in name_equivalence.items():\n",
    "    id = complete_class_ids\n",
    "    for c2 in c2s:\n",
    "        if c1 in complete_class_ids:\n",
    "            complete_class_ids[c2] = complete_class_ids[c1]\n",
    "        elif c2 in complete_class_ids:\n",
    "            complete_class_ids[c1] = complete_class_ids[c2]\n",
    "\n",
    "for script_file in script_file_paths[:2]:\n",
    "    # graph_dict = utils.load_graph_dict('dataset/my_scripts/initial_common.json')\n",
    "    graph = EnvironmentGraph(my_graph)\n",
    "    ## Need to make the script executable with ids before we execute\n",
    "    name_equivalence = load_name_equivalence()\n",
    "    executor = ScriptExecutor(graph, name_equivalence)\n",
    "    script = read_script(script_file)\n",
    "    executable, final_state, graph_state_list = executor.execute_script_file(script_file, w_graph_list=True, ids_by_class=complete_class_ids)\n",
    "    if executable:\n",
    "        print('Writing script outputs for : ',script_file)\n",
    "        dump_one_data(script_file, script, graph_state_list, {}, 'something/custom_graph.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_equivalence['coffee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.evolving_graph.environment import EnvironmentGraph\n",
    "\n",
    "print(len(graph['nodes']))\n",
    "print(len(graph['edges']))\n",
    "print(graph['nodes'][0])\n",
    "classes = {}\n",
    "for node in graph['nodes']:\n",
    "    if node['class_name'] in classes:\n",
    "        classes[node['class_name']] += 1\n",
    "    else:\n",
    "        classes[node['class_name']] = 1\n",
    "print(sorted(list(classes.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.evolving_graph.environment import Relation\n",
    "env = EnvironmentGraph(graph)\n",
    "objects =  env.get_nodes_by_attr('class_name', 'shoes')\n",
    "# print(f'{len(objects)} objects found!')\n",
    "for obj in objects:\n",
    "    print (type(obj))\n",
    "    # stuff = [(r,vals) for (nid,r),vals in env._edge_map.items() if nid == l.id]\n",
    "    # for s in stuff:\n",
    "    #     print (s[0])\n",
    "    #     print (s[1])\n",
    "    #     print()\n",
    "    # nodes = env.get_nodes_from(l, Relation.INSIDE)\n",
    "    # for node in nodes:\n",
    "    #     print (node.class_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import simulation.evolving_graph.utils as utils\n",
    "# from simulation.evolving_graph.scripts import read_script_from_list_string\n",
    "# from simulation.evolving_graph.preparation import AddMissingScriptObjects, AddRandomObjects, ChangeObjectStates\n",
    "# from simulation.evolving_graph.execution import ScriptExecutor, Action\n",
    "\n",
    "# script_list = ['[Walk] <bathroom> (1)', '[Walk] <shower> (2)', '[Find] <shower> (2)']\n",
    "\n",
    "# graph = utils.load_graph('example_graphs/TestScene1_graph.json')\n",
    "# script = read_script_from_list_string(script_list)\n",
    "# for l in script:\n",
    "#     print (str(l))\n",
    "\n",
    "# name_equivalence = utils.load_name_equivalence()\n",
    "# object_placing = utils.load_object_placing()\n",
    "# properties_data = utils.load_properties_data()\n",
    "# executor = ScriptExecutor(graph, name_equivalence)\n",
    "\n",
    "# # Execute script; fails due to a missing object\n",
    "# # state_enum = executor.find_solutions(script)\n",
    "# # state = next(state_enum, None)\n",
    "# # print('Script is {0}executable'.format('not ' if state is None else ''))\n",
    "\n",
    "# # Add missing objects (random)\n",
    "# prepare_1 = AddMissingScriptObjects(name_equivalence, properties_data, object_placing)\n",
    "# print(prepare_1)\n",
    "\n",
    "# # Add 10 random objects\n",
    "# prepare_2 = AddRandomObjects(properties_data, object_placing, choices=10)\n",
    "\n",
    "# # Change states of \"can_open\" and \"has_switch\" objects to\n",
    "# # open/closed, on/off)\n",
    "# prepare_3 = ChangeObjectStates(properties_data)\n",
    "\n",
    "# state_enum = executor.find_solutions(script, [prepare_1, prepare_2, prepare_3])\n",
    "# state = next(state_enum, None)\n",
    "# print('Script is {0}executable'.format('not ' if state is None else ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir dataset/long_scripts_/videos\n",
    "script_file = 'dataset/short_scripts/executable_programs/TrimmedTestScene1_graph/chore/1.txt'\n",
    "process_file_inbuilt(script_file, graph_file_from_script(script_file))\n",
    "for script_file in glob.glob('dataset/long_scripts_/executable_programs/TrimmedTestScene1_graph/batch1/*.txt'):\n",
    "    print(process_file_inbuilt(script_file, graph_file_from_script(script_file)))\n",
    "    file_num = os.path.splitext(os.path.basename(script_file))[0]\n",
    "    copyfile('Output/test/Action_normal.mp4', 'dataset/long_scripts_/videos/'+file_num+'.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulation.evolving_graph.utils as utils\n",
    "from simulation.evolving_graph.scripts import read_script\n",
    "from simulation.evolving_graph.execution import ScriptExecutor\n",
    "\n",
    "for script_file in glob.glob('dataset/long_scripts/executable_programs/TrimmedTestScene1_graph/batch1/*.txt'):\n",
    "    graph = utils.load_graph(graph_file_from_script(script_file))\n",
    "    script = read_script('example_scripts/example_script_3.txt')\n",
    "    name_equivalence = utils.load_name_equivalence()\n",
    "    executor = ScriptExecutor(graph, name_equivalence)\n",
    "    success, state, graph_state_list = executor.execute(script)\n",
    "    if not success:\n",
    "        print('Script is not executable, since {}'.format(executor.info.get_error_string()))\n",
    "    else:\n",
    "        print('Script is executable')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0674fbd63299d983e2055c825b7503b2e6cabbeb669a9608e463c0c32d0bb71"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
