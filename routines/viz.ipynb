{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "min_time = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    " \"brushing_teeth\" : sns.color_palette(palette='pastel')[0], \n",
    " \"showering\" : sns.color_palette(palette='pastel')[1], \n",
    " \"breakfast\" : sns.color_palette(palette='pastel')[2], \n",
    " \"getting_dressed\" : sns.color_palette(palette='pastel')[3], \n",
    " \"computer_work\" : sns.color_palette(palette='pastel')[4], \n",
    " \"lunch\" : sns.color_palette(palette='pastel')[5], \n",
    " \"leave_home\" : sns.color_palette(palette='pastel')[6], \n",
    " \"going_to_the_bathroom\" : sns.color_palette(palette='pastel')[7], \n",
    " \n",
    " \"cleaning\" : sns.color_palette(palette='dark')[0], \n",
    " \"kitchen_cleaning\" : sns.color_palette(palette='dark')[1], \n",
    " \"take_out_trash\" : sns.color_palette(palette='dark')[2], \n",
    " \"laundry\" : sns.color_palette(palette='dark')[3], \n",
    " \"vaccuum_cleaning\" : sns.color_palette(palette='dark')[4], \n",
    " \"wash_dishes\" : sns.color_palette(palette='dark')[5], \n",
    "\n",
    " \"come_home\" : sns.color_palette()[0], \n",
    " \"playing_music\" : sns.color_palette()[1], \n",
    " \"reading\" : sns.color_palette()[2], \n",
    " \"taking_medication\" : sns.color_palette()[3], \n",
    " \"dinner\" : sns.color_palette()[4], \n",
    " \"socializing\" : sns.color_palette()[5], \n",
    " \"listening_to_music\" : sns.color_palette()[6], \n",
    " \"watching_tv\" : sns.color_palette()[7], \n",
    "}\n",
    "\n",
    "def time_human(time_mins):\n",
    "    time_mins = int(round(time_mins))\n",
    "    mins = time_mins%60\n",
    "    time_mins = time_mins//60\n",
    "    hrs = time_mins%24\n",
    "    time_mins = time_mins//24\n",
    "    days = time_mins\n",
    "    h = '{:02d}:{:02d}'.format(hrs,mins)\n",
    "    if days != 0:\n",
    "        h = str(days)+'day - '+h\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hard_worker', 'home_maker', 'work_from_home', 'senior']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = 'data/sourcedRoutines/completePersona0214'\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ind in os.listdir(root_dir):\n",
    "\n",
    "    directory = os.path.join(root_dir, ind)\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    fig.set_size_inches(30,20)\n",
    "\n",
    "    activities_labeled = []\n",
    "\n",
    "    sch_cnt = 0\n",
    "    with open(os.path.join(directory, 'script_usage.txt')) as f:\n",
    "        prev_start = min_time\n",
    "        data = f.readlines()\n",
    "        for line in data[1:]:\n",
    "            _, activity, start, end = line.split(';')\n",
    "            start = float(start.strip())\n",
    "            end = float(end.strip())\n",
    "            end = min(end, 24*60)\n",
    "            if prev_start > end:\n",
    "                prev_start = min_time\n",
    "                sch_cnt += 1\n",
    "            if activity not in activities_labeled:\n",
    "                ax.barh(sch_cnt, end-start, align='center', left=start, label=activity, color=color_map[activity])\n",
    "                activities_labeled.append(activity)\n",
    "            ax.barh(sch_cnt, end-start, align='center', left=start, color=color_map[activity])\n",
    "            prev_start = start\n",
    "        _ = ax.set_xlabel('Time')\n",
    "        _ = ax.set_yticks(np.arange(sch_cnt+1))\n",
    "        _ = ax.set_xticks(np.arange(6*60,24*60, 1*60))\n",
    "        _ = ax.set_xticklabels([time_human(t) for t in np.arange(6*60,24*60, 1*60)])\n",
    "\n",
    "    _ = plt.legend(loc='upper right')\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(ind)\n",
    "    plt.savefig(os.path.join(directory,'schedules.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(6*60, 24*60, 10)\n",
    "num_routines = 60\n",
    "\n",
    "for ind in os.listdir(root_dir):\n",
    "    directory = os.path.join(root_dir, ind)\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    fig.set_size_inches(30,20)\n",
    "\n",
    "    activity_freq = {t:{k:0 for k in color_map.keys()} for t in times}\n",
    "    activities_labeled = []\n",
    "\n",
    "    sch_cnt = 0\n",
    "    with open(os.path.join(directory, 'script_usage.txt')) as f:\n",
    "        data = f.readlines()\n",
    "        for line in data[1:]:\n",
    "            _, activity, start, end = line.split(';')\n",
    "            start = float(start.strip())\n",
    "            end = float(end.strip())\n",
    "            end = min(end, 24*60)\n",
    "            for t in times:\n",
    "                if t>start and t<end:\n",
    "                    activity_freq[t][activity] += 1/num_routines\n",
    "        bottoms = times*0.0\n",
    "        for act in color_map.keys():\n",
    "            freqs = [act_fr[act] for act_fr in activity_freq.values()]\n",
    "            ax.bar(times, freqs, bottom=bottoms, label=act, color=color_map[act], width = 6.5)\n",
    "            bottoms += np.array(freqs)\n",
    "        misclassification_prob = [min(sum(activity_freq[t].values()), 1-max(activity_freq[t].values())) for t in times]\n",
    "        ax.plot(times, misclassification_prob, '-.k', label='misclassification probability')\n",
    "        _ = ax.set_xlabel('Time')\n",
    "        _ = ax.set_xticks(np.arange(6*60,24*60, 1*60))\n",
    "        _ = ax.set_xticklabels([time_human(t) for t in np.arange(6*60,24*60, 1*60)])\n",
    "\n",
    "    avg_miscl_prob = sum(misclassification_prob)/len(misclassification_prob)\n",
    "    _ = plt.legend(loc='upper right')\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(ind+'-- avg. misclassification probability = '+'{:1.3f}'.format(avg_miscl_prob))\n",
    "    plt.savefig(os.path.join(directory,'schedule_distribution.jpg'))\n",
    "\n",
    "    with open(os.path.join(directory, 'info.json')) as f:\n",
    "        info = json.load(f)\n",
    "    info['misclassification_prob'] = avg_miscl_prob\n",
    "    with open(os.path.join(directory, 'info.json'), 'w') as f:\n",
    "        json.dump(info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hard_worker\n",
      "Starts alpha :  (-0.25333161086878286, array([-0.762,  0.165]))\n",
      "Ends alpha :  (-0.3180322176872612, array([-0.853,  0.122]))\n",
      "Mids alpha :  (-0.28610989877176735, array([-0.808,  0.143]))\n",
      "\n",
      "home_maker\n",
      "Starts alpha :  (0.27387452903495, array([-0.02 ,  0.516]))\n",
      "Ends alpha :  (0.2577400544215982, array([-0.042,  0.505]))\n",
      "Mids alpha :  (0.26649188547503605, array([-0.03 ,  0.511]))\n",
      "\n",
      "work_from_home\n",
      "Starts alpha :  (-0.004711898737058977, array([-0.412,  0.33 ]))\n",
      "Ends alpha :  (-0.07485901838947896, array([-0.51 ,  0.284]))\n",
      "Mids alpha :  (-0.03709366857108142, array([-0.457,  0.309]))\n",
      "\n",
      "senior\n",
      "Starts alpha :  (0.0633260971093551, array([-0.316,  0.375]))\n",
      "Ends alpha :  (0.044232046626804127, array([-0.342,  0.363]))\n",
      "Mids alpha :  (0.05324375717840743, array([-0.33 ,  0.369]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pingouin import cronbach_alpha\n",
    "\n",
    "for ind in os.listdir(root_dir):\n",
    "\n",
    "    starts = [{k:[] for k in color_map.keys()}]\n",
    "    ends = [{k:[] for k in color_map.keys()}]\n",
    "    \n",
    "\n",
    "    directory = os.path.join(root_dir, ind)\n",
    "\n",
    "    activities_labeled = []\n",
    "    sch_cnt = 0\n",
    "    with open(os.path.join(directory, 'script_usage.txt')) as f:\n",
    "        prev_start = min_time\n",
    "        data = f.readlines()\n",
    "        for line in data[1:]:\n",
    "            _, activity, start, end = line.split(';')\n",
    "            start = float(start.strip())\n",
    "            end = float(end.strip())\n",
    "            end = min(end, 24*60)\n",
    "            starts[-1][activity].append(start)\n",
    "            ends[-1][activity].append(end)\n",
    "            if prev_start > end:\n",
    "                prev_start = min_time\n",
    "                sch_cnt += 1\n",
    "                starts.append({k:[] for k in color_map.keys()})\n",
    "                ends.append({k:[] for k in color_map.keys()})\n",
    "            prev_start = start\n",
    "    \n",
    "    features_st = [[] for _ in range(sch_cnt)]\n",
    "    features_end = [[] for _ in range(sch_cnt)]\n",
    "    for activity in color_map.keys():\n",
    "        for i in range(sch_cnt):\n",
    "            features_st[i] += (starts[i][activity])\n",
    "            features_end[i] += (ends[i][activity])\n",
    "        max_len = max([len(fst) for fst in features_st])\n",
    "        for i in range(sch_cnt):\n",
    "            features_st[i] += [float('nan') for _ in range(max_len-len(features_st[i]))]\n",
    "            # features_st[i] += [0 for _ in range(max_len-len(features_st[i]))]\n",
    "            features_end[i] += [float('nan') for _ in range(max_len-len(features_end[i]))]\n",
    "            # features_end[i] += [0 for _ in range(max_len-len(features_end[i]))]\n",
    "\n",
    "    features_st = pd.DataFrame(np.array(features_st))\n",
    "    # features_st['name'] = np.arange(sch_cnt)\n",
    "    features_end = pd.DataFrame(np.array(features_end))\n",
    "    # features_end['name'] = np.arange(sch_cnt)\n",
    "    features_mid = pd.DataFrame(np.array((features_st + features_end)/2))\n",
    "\n",
    "\n",
    "    # print(features_end.head())\n",
    "    print()\n",
    "    print(ind)\n",
    "    print('Starts alpha : ',cronbach_alpha(data=features_st.fillna(features_st.median())))\n",
    "    print('Ends alpha : ',cronbach_alpha(data=features_end.fillna(features_end.median())))\n",
    "    print('Mids alpha : ',cronbach_alpha(data=features_mid.fillna(features_mid.median())))\n",
    "\n",
    "\n",
    "    # for i in range(sch_cnt):\n",
    "    #     print(features_st[i])\n",
    "    #     print(features_end[i])\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "target_dir = 'data/dataVisuals'\n",
    "for root, dirs, files in os.walk('data/sourcedRoutines'):\n",
    "    for f in files:\n",
    "        if f.endswith('.jpg'):\n",
    "            target_dir = root.replace('sourcedRoutines','dataVisuals')\n",
    "            if not os.path.exists(target_dir):\n",
    "                os.makedirs(target_dir)\n",
    "            shutil.copyfile(os.path.join(root,f), os.path.join(target_dir,f))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0674fbd63299d983e2055c825b7503b2e6cabbeb669a9608e463c0c32d0bb71"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
