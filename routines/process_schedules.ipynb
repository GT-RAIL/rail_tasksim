{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from math import floor\n",
    "\n",
    "from ScheduleDistributionSampler import ScheduleDistributionSampler, activity_map, start_times, KLdivergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data from AMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/personaBasedSchedules/corrected_histograms.json') as f:\n",
    "    corrected_histograms = json.load(f)\n",
    "\n",
    "activities = list(set(activity_map.values()))\n",
    "activities.remove(None)\n",
    "\n",
    "fig, ind_plot = plt.subplots(len(corrected_histograms.keys()), len(activities), sharex=True, sharey=True)\n",
    "fig.set_size_inches(80, 50)\n",
    "\n",
    "for i,(id,act_hists) in enumerate(corrected_histograms.items()):\n",
    "    for j,(activity,data) in enumerate(act_hists.items()):\n",
    "        ind_plot[i][j].bar(start_times, data)\n",
    "        ind_plot[i][j].set_yticks([])\n",
    "        ind_plot[i][j].set_xticks([])\n",
    "        if i==0:\n",
    "            ind_plot[i][j].set_title(activity.replace('_','\\n'))\n",
    "    ind_plot[i][0].set_ylabel(id, rotation=0, labelpad=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_together(list_of_freqs, ax):\n",
    "    for i,freqs in enumerate(list_of_freqs):\n",
    "        freq_exist = np.array(start_times)[np.array(freqs) == 1]\n",
    "        ax.plot(freq_exist,freq_exist*0 + i, '.')\n",
    "        if sum(freqs) == 0:\n",
    "            ax.plot(np.array(start_times),np.array(start_times)*0 + i, linewidth = 0.3, color=[0.8,0.8,0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "individual_features = {}\n",
    "\n",
    "morning = np.array([1 if i<12 else 0 for i in range(6,24)])\n",
    "afternoon = np.array([1 if i>=12 and i<18 else 0 for i in range(6,24)])\n",
    "evening = np.array([1 if i>=18 else 0 for i in range(6,24)])\n",
    "\n",
    "for act in activities:\n",
    "    individual_features[act] = {}\n",
    "    for indiv, act_hist in corrected_histograms.items():\n",
    "        feat = []\n",
    "        seq = np.argwhere(act_hist[act]).reshape(-1)\n",
    "        if len(seq) > 1:\n",
    "            gm = GaussianMixture(n_components=2).fit(seq.reshape(-1,1))\n",
    "            gm_means = gm.means_.reshape(-1)\n",
    "            gm_inds = gm_means.argsort()[::-1]\n",
    "            gm_means = deepcopy(gm_means[gm_inds]).reshape(-1)\n",
    "        elif len(seq) == 1:\n",
    "            gm_means = np.ones((2,)) * -1\n",
    "            gm_means[0] = deepcopy(seq[0])\n",
    "            gm_means[1] = deepcopy(seq[0])\n",
    "        else:\n",
    "            gm_means = np.ones((2,)) * -24\n",
    "        this_act = np.array(act_hist[act])\n",
    "        feat += [sum(morning*this_act), sum(afternoon*this_act), sum(evening*this_act)]\n",
    "        feat += list(gm_means)\n",
    "        individual_features[act][indiv] = np.array(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_histograms = {}\n",
    "n_clusters = 4\n",
    "\n",
    "if not os.path.exists('data/personaBasedSchedules/histograms/'):\n",
    "    os.makedirs('data/personaBasedSchedules/histograms/')\n",
    "\n",
    "for activity in activities:\n",
    "    individual_names = list(individual_features[activity].keys())\n",
    "    individual_features_array = np.array(np.array(list(individual_features[activity].values())))\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(individual_features_array)\n",
    "    clusters = []\n",
    "    for n in range(n_clusters):\n",
    "        clusters.append([name for i,name in enumerate(individual_names) if kmeans.labels_[i]==n])\n",
    "\n",
    "    clusters_used = []\n",
    "    cluster_histograms[activity] = []\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        avg = np.array([corrected_histograms[ind][activity] for ind in cluster]).mean(axis=0)\n",
    "        if len(cluster) > 3:\n",
    "            cluster_histograms[activity].append(list(avg))\n",
    "            clusters_used.append(cluster)\n",
    "            \n",
    "    fig, axs = plt.subplots(2, len(cluster_histograms[activity]), sharex=True)\n",
    "    axs = axs.reshape(2,-1)\n",
    "    fig.set_size_inches(20, 5)\n",
    "    fig.suptitle(f'{activity}')\n",
    "    for i,(avg,cluster) in enumerate(zip(cluster_histograms[activity],clusters_used)):\n",
    "        axs[1][i].plot(start_times, avg, '-.k')\n",
    "        axs[1][i].set_ylim([0,1])\n",
    "        plot_together([corrected_histograms[ind][activity] for ind in cluster], axs[0][i])\n",
    "        axs[0][i].set_title(f'{len(cluster)}/21')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('data/personaBasedSchedules/histograms/'+activity+'.jpg')\n",
    "    \n",
    "\n",
    "with open('data/personaBasedSchedules/cluster_histograms.json','w') as f:\n",
    "    json.dump(cluster_histograms, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize for distinct persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/personaBasedSchedules/cluster_histograms.json') as f:\n",
    "    cluster_histograms = json.load(f)\n",
    "activities = list(cluster_histograms.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 5\n",
    "N = 20\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram(persona):\n",
    "    return {act:cluster_histograms[act][choice] for act,choice in zip(activities,persona)}\n",
    "    \n",
    "def get_random_persona():\n",
    "    persona = []\n",
    "    for act in activities:\n",
    "        activity_options = np.arange(len(cluster_histograms[act]))\n",
    "        persona.append(random.choice(activity_options))\n",
    "    return persona\n",
    "\n",
    "def get_candidate():\n",
    "    return [get_random_persona() for _ in range(P)]\n",
    "\n",
    "def get_initial_pool():\n",
    "    return [get_candidate() for _ in range(N)]\n",
    "\n",
    "def valid(persona):\n",
    "    leave_idx = persona[activities.index('leave_home')]\n",
    "    come_idx = persona[activities.index('come_home')]\n",
    "    leave_sum = np.sum(cluster_histograms['leave_home'][leave_idx])\n",
    "    come_sum = np.sum(cluster_histograms['come_home'][come_idx])\n",
    "    if leave_sum == 0 and come_sum == 0:\n",
    "        return 1\n",
    "    if (leave_sum == 0 and come_sum > 0) or (leave_sum > 0 and come_sum == 0):\n",
    "        return 0\n",
    "    leave_mean_cumul = np.cumsum(cluster_histograms['leave_home'][leave_idx])\n",
    "    come_mean_cumul = np.cumsum(cluster_histograms['come_home'][come_idx])\n",
    "    leave_mean = int(max(np.argwhere(leave_mean_cumul<0.5)))\n",
    "    come_mean = int(max(np.argwhere(come_mean_cumul<0.5)))\n",
    "    return float(come_mean > leave_mean)\n",
    "\n",
    "def fittness_matrix(candidate):\n",
    "    kl_mat = np.zeros((len(candidate), len(candidate)))\n",
    "    for i1,per1 in enumerate(candidate):\n",
    "        for i2,per2 in enumerate(candidate):\n",
    "            if i1==i2:\n",
    "                kl_mat[i1][i2] = 0 # personaFitness(get_histogram(per1))\n",
    "            else:\n",
    "                kl_mat[i1][i2] = KLdivergence(get_histogram(per1), get_histogram(per2))\n",
    "    return kl_mat\n",
    "\n",
    "def fitness(candidate):\n",
    "    kl_mat = fittness_matrix(candidate)\n",
    "    v = 1\n",
    "    for per in candidate:\n",
    "        v *= valid(per)\n",
    "    return np.mean(kl_mat) * v\n",
    "\n",
    "def get_pool_fitness(pool):\n",
    "    return np.array([fitness(candidate) for candidate in pool])\n",
    "\n",
    "def get_best_k(pool, k=K):\n",
    "    pool_fitness = get_pool_fitness(pool)\n",
    "    best_k_idx = pool_fitness.argsort()[::-1][:k]\n",
    "    return [pool[idx] for idx in best_k_idx], pool_fitness[best_k_idx]\n",
    "\n",
    "def mate(parents):\n",
    "    random.shuffle(parents)\n",
    "    children = [candidate[0:floor(P/2)] for candidate in parents]\n",
    "    random.shuffle(parents)\n",
    "    children = [prev+candidate[floor(P/2):] for candidate, prev in zip(parents,children)]\n",
    "    return children\n",
    "\n",
    "def mutate(pool):\n",
    "    for candidate in pool:\n",
    "        if random.random() < 0.05:\n",
    "            candidate[random.choice(np.arange(P))] = get_random_persona()\n",
    "    return pool\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_finds = []\n",
    "best_fitnesses = []\n",
    "for rst in range(5):\n",
    "    avg_fitness = []\n",
    "    pool = get_initial_pool()\n",
    "    for iter in range(1000):\n",
    "        parents, fitnesses = get_best_k(pool)\n",
    "        avg_fitness.append(np.mean(fitnesses))\n",
    "        if iter%100 == 0:\n",
    "            print(f'Iteration {iter} : {avg_fitness[-1]}')\n",
    "        children = mate(parents)\n",
    "        children = mutate(children)\n",
    "        pool = parents + children\n",
    "\n",
    "    plt.plot(avg_fitness, label=f'run {rst}')\n",
    "\n",
    "    best_candidate, best_fittness = get_best_k(pool,1)\n",
    "    best_candidate = (best_candidate[0])\n",
    "    result = [[int(idx) for idx in cand] for cand in best_candidate]\n",
    "    best_finds.append(result)\n",
    "    best_fitnesses.append(best_fittness)\n",
    "\n",
    "plt.legend()\n",
    "best_rst = np.array(best_fitnesses).argmax()\n",
    "candidate = best_finds[best_rst]\n",
    "fittness_matrix(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona = {}\n",
    "for i,cand in enumerate(result):\n",
    "    persona['persona'+str(i)] = {a:idx for a,idx in zip(activities, cand)}\n",
    "\n",
    "with open('data/personaBasedSchedules/optimized_persona.json', 'w') as f:\n",
    "    json.dump(persona, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScheduleDistributionSampler(type='persona0').plot()\n",
    "ScheduleDistributionSampler(type='persona1').plot()\n",
    "ScheduleDistributionSampler(type='persona2').plot()\n",
    "ScheduleDistributionSampler(type='persona3').plot()\n",
    "ScheduleDistributionSampler(type='persona4').plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f2dbfa5ef75a9144d7b0485e8c79d6707cb4300dbf38d3b3596c375ba449bc0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
