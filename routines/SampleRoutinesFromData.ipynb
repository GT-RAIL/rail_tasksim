{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample scripts for full routines from sourced scripts and sourced schedules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from random import random\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../simulation')\n",
    "\n",
    "from evolving_graph.scripts import Script\n",
    "import evolving_graph.utils as utils\n",
    "from evolving_graph.execution import ScriptExecutor\n",
    "from evolving_graph.environment import EnvironmentGraph\n",
    "\n",
    "from GraphReader import GraphReader, init_graph_file, scene_num\n",
    "from ProgramExecutor import read_program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mins(mins, hrs, day=0):\n",
    "    return (((day)*24)+hrs)*60+mins\n",
    "\n",
    "def time_human(time_mins):\n",
    "    mins = time_mins%60\n",
    "    time_mins = time_mins//60\n",
    "    hrs = time_mins%24\n",
    "    time_mins = time_mins//24\n",
    "    days = time_mins\n",
    "    h = '{:02d}:{:02d}'.format(hrs,mins)\n",
    "    if days != 0:\n",
    "        h = str(days)+'day - '+h\n",
    "    return h\n",
    "\n",
    "def day_num(day_of_week):\n",
    "    return {'Monday':0,'Tuesday':1,'Wednesday':2,'Thursday':3,'Friday':4,'Saturday':5,'Sunday':6}[day_of_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_graph = GraphReader(graph_file=init_graph_file)\n",
    "print(f'Using scene {int(scene_num)-1}, i.e. \\'TestScene{scene_num}\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}\n",
    "info['dt'] = 10   # minutes\n",
    "info['num_train_routines'] = 5\n",
    "info['num_test_routines'] = 1\n",
    "info['weekend_days'] = [day_num(day) for day in ['Saturday','Sunday']]\n",
    "info['start_time'] = time_mins(mins=0, hrs=6)\n",
    "info['interleaving'] = True\n",
    "info['only_used_objects'] = True\n",
    "info['graphs_dt_apart'] = True\n",
    "\n",
    "ignore_classes = ['floor','wall','ceiling','character']\n",
    "utilized_object_ids = set()\n",
    "\n",
    "edge_classes = [\"INSIDE\", \"ON\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activity():\n",
    "    def __init__(self, name, time, script_file=None, verbose=False):\n",
    "        self.name = name\n",
    "        start_time = time_mins(time[0][1], time[0][0])\n",
    "        end_time = time_mins(time[1][1], time[1][0])\n",
    "        directory = os.path.join('data/sourcedScriptsByActivity', name)\n",
    "        if script_file is None:\n",
    "            script_file = np.random.choice(os.listdir(directory))\n",
    "            if verbose:\n",
    "                print(f'Picking script {script_file} for {name}')\n",
    "            headers, self.scripts, self.obj_use, _ = read_program(os.path.join(directory,script_file), init_graph.node_map)\n",
    "        def sample_duration(header):\n",
    "            durations = (header).split('-')\n",
    "            assert len(durations)==2, f\"Invalid comment {header} in {name}->{script_file}\"\n",
    "            duration_min = int(durations[0].strip())\n",
    "            duration_max = int(durations[1].strip())\n",
    "            duration_sampled = (random() * (duration_max-duration_min) + duration_min)\n",
    "            return duration_sampled\n",
    "        self.durations = [sample_duration(header) for header in headers]\n",
    "        def valid_times(times):\n",
    "            for time, next_time, duration in zip(times[:-1], times[1:], self.durations[:-1]):\n",
    "                if next_time - time <= duration:\n",
    "                    return False\n",
    "                if info['graphs_dt_apart'] and next_time - time <= info['dt']:\n",
    "                    return False\n",
    "            return True\n",
    "        valid = False\n",
    "        while not valid:\n",
    "            times = (np.random.rand(len(headers)) * (end_time-start_time) + start_time).round().astype(int)\n",
    "            times.sort()\n",
    "            valid = valid_times(times)\n",
    "        self.times = times\n",
    "    \n",
    "    def get_action_info(self):\n",
    "        detailed_actions = []\n",
    "        for t,d,scr,obj_s,obj_e in zip(self.times, self.durations, self.scripts, self.obj_use['start'], self.obj_use['end']):\n",
    "            t2 = int(round(t+d))\n",
    "            detailed_actions.append({'time_from':t, 'time_to':t2, 'name':self.name, 'script':scr, 'time_from_h':time_human(t), 'time_to_h':time_human(t2), 'start_using':obj_s, 'end_using':obj_e})\n",
    "        return detailed_actions\n",
    "\n",
    "class Schedule():\n",
    "    def __init__(self, type=None):\n",
    "        assert type == None or type in ['weekday','weekend']\n",
    "        schedule_options = []\n",
    "        for (root,_,files) in os.walk('data/sourcedSchedules'):\n",
    "            if type is not None and type not in root:\n",
    "                continue\n",
    "            schedule_options += [os.path.join(root,f) for f in files]\n",
    "        self.schedule_file_path = np.random.choice(schedule_options)\n",
    "        with open(self.schedule_file_path) as f:\n",
    "            schedule = json.load(f)\n",
    "        self.activities = [Activity(act_name, act_time) for act_name,act_time in schedule.items()]\n",
    "    \n",
    "    def get_combined_script(self, verbose=False):\n",
    "        all_actions = []\n",
    "        object_use_times = {}\n",
    "        for act in self.activities:\n",
    "            all_actions += act.get_action_info()\n",
    "        all_actions.sort(key = lambda x : x['time_from'])\n",
    "        if verbose:\n",
    "            for a in all_actions:\n",
    "                print (a['time_from_h']+' to '+a['time_to_h']+' : '+a['name'])\n",
    "                print ('Started using : '+str(a['start_using'])+'; Finished using : '+str(a['end_using']))\n",
    "                for l in a['script']:\n",
    "                    print(' - ',l)\n",
    "        valid=True\n",
    "        for end_time, next_start in zip([a['time_to'] for a in all_actions[:-1]], [a['time_from'] for a in all_actions[1:]]):\n",
    "            if end_time > next_start:\n",
    "                valid = False\n",
    "                if verbose:\n",
    "                    print(f'End time {end_time} of an activity, exceeds start time {next_start} of next activity')\n",
    "                break\n",
    "        return all_actions, valid\n",
    "\n",
    "def get_graphs(all_actions, verbose=False):\n",
    "    with open (init_graph_file,'r') as f:\n",
    "        init_graph_dict = json.load(f)\n",
    "    name_equivalence = utils.load_name_equivalence()\n",
    "    graphs = [EnvironmentGraph(init_graph_dict).to_dict()]\n",
    "    objects_in_use = [[]]\n",
    "    current_objects = []\n",
    "    for action in all_actions:\n",
    "        if verbose:\n",
    "            print('## Executing '+action['name']+' from '+action['time_from_h']+' to '+action['time_to_h'])\n",
    "            print ('Started using : '+str(action['start_using'])+'; Finished using : '+str(action['end_using']))\n",
    "            for l in action['script']:\n",
    "                print (l)\n",
    "        ## execute the script\n",
    "        executor = ScriptExecutor(EnvironmentGraph(graphs[-1]), name_equivalence)\n",
    "        success, state, _ = executor.execute(Script(action['script']), w_graph_list=False)\n",
    "        ## update the list of objects currently in use\n",
    "        for obj in action['start_using']:\n",
    "            current_objects.append(obj)\n",
    "        for obj in action['end_using']:\n",
    "            current_objects.remove(obj)\n",
    "        ## save the iteration results\n",
    "        graphs.append(state.to_dict())\n",
    "        objects_in_use.append([{'id':o[0], 'name':o[1]} for o in current_objects])\n",
    "        update_used_objects(graphs[-2],graphs[-1])\n",
    "        if verbose:\n",
    "            print_graph_difference(graphs[-2],graphs[-1])\n",
    "            print('Currently using : ',current_objects)\n",
    "            input('Press something...')\n",
    "        if not success:\n",
    "            print('Execution of {} starting at {} failed because {}'.format(action['name'], action['time_from_h'], executor.info.get_error_string()))\n",
    "\n",
    "    return graphs, objects_in_use, success\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ignored_classes(graphs):\n",
    "    clipped_graphs = []\n",
    "    for graph in graphs:\n",
    "        clipped_graphs.append({'nodes':[],'edges':[]})\n",
    "        ignore_ids = []\n",
    "        for node in graph['nodes']:\n",
    "            if node['class_name'] in ignore_classes:\n",
    "                ignore_ids.append(node['id'])\n",
    "            elif info['only_used_objects'] and node['id'] not in utilized_object_ids:\n",
    "                ignore_ids.append(node['id'])\n",
    "            else:\n",
    "                clipped_graphs[-1]['nodes'].append(node)\n",
    "        for edge in graph['edges']:\n",
    "            if edge['from_id'] in ignore_ids or edge['to_id'] in ignore_ids:\n",
    "                continue\n",
    "            clipped_graphs[-1]['edges'].append(edge)\n",
    "    return clipped_graphs\n",
    "\n",
    "def class_from_id(graph, id):\n",
    "    lis = [n['class_name'] for n in graph['nodes'] if n['id']==id]\n",
    "    if len(lis) > 0:\n",
    "        return lis[0]\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "def print_graph_difference(g1,g2):\n",
    "    edges_removed = [e for e in g1['edges'] if e not in g2['edges']]\n",
    "    edges_added = [e for e in g2['edges'] if e not in g1['edges']]\n",
    "    nodes_removed = [n for n in g1['nodes'] if n['id'] not in [n2['id'] for n2 in g2['nodes']]]\n",
    "    nodes_added = [n for n in g2['nodes'] if n['id'] not in [n2['id'] for n2 in g1['nodes']]]\n",
    "\n",
    "    for n in nodes_removed:\n",
    "        print ('Removed node : ',n)\n",
    "    for n in nodes_added:\n",
    "        print ('Added node   : ',n)\n",
    "    for e in edges_removed:\n",
    "        c1 = class_from_id(g1,e['from_id'])\n",
    "        c2 = class_from_id(g1,e['to_id'])\n",
    "        if c1 != 'character' and c2 != 'character' and e['relation_type'] in edge_classes:\n",
    "            print ('Removed edge : ',c1,e['relation_type'],c2)\n",
    "    for e in edges_added:\n",
    "        c1 = class_from_id(g2,e['from_id'])\n",
    "        c2 = class_from_id(g2,e['to_id'])\n",
    "        if c1 != 'character' and c2 != 'character' and e['relation_type'] in edge_classes:\n",
    "            print ('Added edge   : ',c1,e['relation_type'],c2)\n",
    "\n",
    "def update_used_objects(g1,g2):\n",
    "    edges_removed = [e for e in g1['edges'] if e not in g2['edges']]\n",
    "    edges_added = [e for e in g2['edges'] if e not in g1['edges']]\n",
    "    nodes_removed = [n for n in g1['nodes'] if n['id'] not in [n2['id'] for n2 in g2['nodes']]]\n",
    "    nodes_added = [n for n in g2['nodes'] if n['id'] not in [n2['id'] for n2 in g1['nodes']]]\n",
    "    for n in nodes_removed:\n",
    "        utilized_object_ids.add(n['id'])\n",
    "    for n in nodes_added:\n",
    "        utilized_object_ids.add(n['id'])\n",
    "    for e in edges_removed:\n",
    "        if e['relation_type'] in edge_classes and class_from_id(g1,e['from_id'])!='character' and class_from_id(g1,e['to_id'])!='character':\n",
    "            utilized_object_ids.add(e['from_id'])\n",
    "            utilized_object_ids.add(e['to_id'])\n",
    "    for e in edges_added:\n",
    "        if e['relation_type'] in edge_classes and class_from_id(g1,e['from_id'])!='character' and class_from_id(g1,e['to_id'])!='character':\n",
    "            utilized_object_ids.add(e['from_id'])\n",
    "            utilized_object_ids.add(e['to_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_DIR = 'data/sourcedRoutines/temp'\n",
    "if os.path.exists(TEMP_DIR):\n",
    "    shutil.rmtree(TEMP_DIR)\n",
    "\n",
    "os.makedirs(TEMP_DIR)\n",
    "scripts_train_dir = os.path.join(TEMP_DIR,'scripts_train')\n",
    "scripts_test_dir = os.path.join(TEMP_DIR,'scripts_test')\n",
    "os.makedirs(scripts_train_dir)\n",
    "os.makedirs(scripts_test_dir)\n",
    "\n",
    "def make_routine(routine_num, scripts_dir):\n",
    "    while True:\n",
    "        day = np.random.choice(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n",
    "        day_number = day_num(day)\n",
    "        day_type = 'weekend' if day_number in info['weekend_days'] else 'weekday'\n",
    "        s = Schedule(day_type)\n",
    "        actions, valid = s.get_combined_script()\n",
    "        if not valid:\n",
    "            # print(f'Script failed due to time clash')\n",
    "            continue\n",
    "        graphs, objects_in_use, success = get_graphs(actions)\n",
    "        if not success:\n",
    "            # print(f'Script failed due to execution failure')\n",
    "            continue\n",
    "        times = [a['time_to'] for a in actions]\n",
    "        script_file = os.path.join(scripts_dir,'{:03d}'.format(routine_num)+'.txt')\n",
    "        with open(script_file, 'w') as f:\n",
    "            f.write(day+' schedule generated from '+s.schedule_file_path+'\\n\\n\\n')\n",
    "            for action in actions:\n",
    "                f.write('## '+action['name']+' from '+action['time_from_h']+' to '+action['time_to_h']+'\\n')\n",
    "                for l in action['script']:\n",
    "                    f.write(str(l)[:-4]+'\\n')\n",
    "        print(f'Generated script {script_file}')\n",
    "        return ({'times':times,'graphs':graphs, 'objects_in_use':objects_in_use})\n",
    "\n",
    "\n",
    "data_train = []\n",
    "for routine_num in range(info['num_train_routines']):\n",
    "    data_train.append(make_routine(routine_num, scripts_train_dir))\n",
    "\n",
    "data_test = []\n",
    "for routine_num in range(info['num_test_routines']):\n",
    "    data_test.append(make_routine(routine_num, scripts_test_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refercnce_full_graph = data_test[0]['graphs'][0]\n",
    "\n",
    "## update utilized objects to include complete tree\n",
    "check_ids = utilized_object_ids\n",
    "while len(check_ids) > 0:\n",
    "    next_check_ids = set()\n",
    "    for e in refercnce_full_graph['edges']:\n",
    "        if e['from_id'] in check_ids and e['relation_type'] in edge_classes:\n",
    "            utilized_object_ids.add(e['to_id'])\n",
    "            next_check_ids.add(e['to_id'])\n",
    "    check_ids = next_check_ids\n",
    "\n",
    "for data in data_train:\n",
    "    data['graphs'] = remove_ignored_classes(data['graphs'])\n",
    "with open(os.path.join(TEMP_DIR,'routines_train.json'), 'w') as f:\n",
    "    json.dump(data_train, f)\n",
    "\n",
    "for data in data_test:\n",
    "    data['graphs'] = remove_ignored_classes(data['graphs'])\n",
    "with open(os.path.join(TEMP_DIR,'routines_test.json'), 'w') as f:\n",
    "    json.dump(data_test, f)\n",
    "\n",
    "refercnce_graph = data_test[0]['graphs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = refercnce_graph['nodes']\n",
    "with open(os.path.join(TEMP_DIR,'classes.json'), 'w') as f:\n",
    "    json.dump({\"nodes\":nodes, \"edges\":edge_classes}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['num_nodes'] = len(nodes)\n",
    "search_objects = [n for n in nodes if n['id'] in utilized_object_ids and n['category']=='placable_objects']\n",
    "info['search_object_ids'] = [n['id'] for n in search_objects]\n",
    "info['search_object_names'] = [n['class_name'] for n in search_objects]\n",
    "for k,v in info.items():\n",
    "    print(k,' : ',v)\n",
    "with open(os.path.join(TEMP_DIR,'info.json'), 'w') as f:\n",
    "    json.dump(info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = 'data/sourcedRoutines/sourcedTrial'\n",
    "\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    shutil.rmtree(DATASET_DIR)\n",
    "shutil.move(TEMP_DIR, DATASET_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION_DIR = os.path.join('../../SpatioTemporalObjectTracking/data/',os.path.basename(DATASET_DIR))\n",
    "\n",
    "if not os.path.exists(DESTINATION_DIR):\n",
    "    shutil.copytree(DATASET_DIR, DESTINATION_DIR)\n",
    "    print('Successfully copied to ',DESTINATION_DIR)\n",
    "else:\n",
    "    overwrite = input(DESTINATION_DIR+' already exists. Do you want to overwrite it? (y/n)')\n",
    "    if overwrite:\n",
    "        shutil.rmtree(DESTINATION_DIR)\n",
    "        shutil.copytree(DATASET_DIR, DESTINATION_DIR)\n",
    "        print('Successfully copied to ',DESTINATION_DIR)\n",
    "    else:\n",
    "        print('Skipping copy')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cffe7c9c5b16c39ad8342f96bfb2ea1c3f8c12324c2ee5fa5fb5a776efa78cb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
